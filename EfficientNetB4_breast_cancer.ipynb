{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "low_res_effnet.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ij2e83tegNic",
        "outputId": "305ed192-a5b9-400e-c98f-71e39a82de2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        }
      },
      "source": [
        "!pip install efficientnet\n",
        "!pip install keras-radam\n",
        "!pip install adabound\n",
        "!pip install keras-adabound"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: efficientnet in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from efficientnet) (0.16.2)\n",
            "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /usr/local/lib/python3.6/dist-packages (from efficientnet) (1.0.8)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (2.4)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (7.0.0)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (1.4.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (1.1.1)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (3.2.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet) (2.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.18.5)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image->efficientnet) (4.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (0.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.12.0)\n",
            "Requirement already satisfied: keras-radam in /usr/local/lib/python3.6/dist-packages (0.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-radam) (1.18.5)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras-radam) (2.3.1)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-radam) (1.4.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-radam) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-radam) (1.1.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras-radam) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras-radam) (3.13)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-radam) (1.12.0)\n",
            "Requirement already satisfied: adabound in /usr/local/lib/python3.6/dist-packages (0.0.5)\n",
            "Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from adabound) (1.5.1+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.0->adabound) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.0->adabound) (1.18.5)\n",
            "Requirement already satisfied: keras-adabound in /usr/local/lib/python3.6/dist-packages (0.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-adabound) (1.18.5)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras-adabound) (2.3.1)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-adabound) (1.4.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-adabound) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-adabound) (1.1.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras-adabound) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras-adabound) (3.13)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-adabound) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCru6Pu2hHvg",
        "outputId": "1fe6723f-09f6-48ff-f72a-1c873ace7d74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        }
      },
      "source": [
        "!pip install tensorflow==1.14\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==1.14 in /usr/local/lib/python3.6/dist-packages (1.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.12.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.18.5)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.0.8)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (3.10.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.8.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.3.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.34.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.12.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.14.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.2.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.30.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.9.0)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.14.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.14) (47.3.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.2.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (1.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.1.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'1.14.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yl8uAlT1f9fe"
      },
      "source": [
        "import tensorflow as tf\n",
        "import shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import os\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Dropout, Activation, BatchNormalization, Flatten, ReLU\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.optimizers import Adam, SGD\n",
        "import efficientnet.keras as enet\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras_radam import RAdam\n",
        "from keras_adabound import AdaBound\n",
        "# from adabound import AdaBound\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7rwDaG8gGFO"
      },
      "source": [
        "def idx_generator(labels1):\n",
        "    ''' Condition on labels '''\n",
        "    idx_0 = np.where(labels1 == 0)[0]\n",
        "    idx_1 = np.where(labels1 == 1)[0]\n",
        "    malignant_idx = np.random.choice(idx_0, len(idx_1), replace=False)\n",
        "    benign_idx = np.random.choice(idx_1, len(idx_1), replace=False)\n",
        "\n",
        "    ''' Concat data '''\n",
        "    labels_idx1 = np.concatenate([malignant_idx, benign_idx])\n",
        "    ''' Random labels '''\n",
        "    labels_idx1 = np.random.choice(labels_idx1, len(labels_idx1), replace=False)\n",
        "    return labels_idx1\n",
        "\n",
        "\n",
        "def dataset_equalizer(dataset11, labels11):\n",
        "    ''' Choose malignant and benign data '''\n",
        "    # dataset11, labels11 = data_loader(t00)\n",
        "    labels_idx11 = idx_generator(labels11)\n",
        "    labels11 = labels11[labels_idx11]\n",
        "    dataset11 = dataset11[labels_idx11]\n",
        "    return dataset11, labels11\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkRtiqC5grIg"
      },
      "source": [
        "''' Seed for reproducible results '''\n",
        "# Seed value\n",
        "# Apparently you may use different seed values at each stage\n",
        "seed_value = 0\n",
        "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
        "import os\n",
        "\n",
        "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
        "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
        "import random\n",
        "\n",
        "random.seed(seed_value)\n",
        "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
        "np.random.seed(seed_value)\n",
        "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
        "tf.random.set_random_seed(seed_value)\n",
        "# for later versions:\n",
        "# tf.compat.v1.set_random_seed(seed_value)\n",
        "# 5. Configure a new global `tensorflow` session\n",
        "from keras import backend as K\n",
        "\n",
        "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
        "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
        "K.set_session(sess)\n",
        "# for later versions:\n",
        "# session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
        "# sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
        "# tf.compat.v1.keras.backend.set_session(sess)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jyc_R-PJi9DX",
        "outputId": "a8303f74-15f5-4c2f-e640-da796e009eb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fh1ExC6AgrM2",
        "outputId": "95a137e4-e89a-4f1d-efca-35c2284a31a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "''' Read labels '''\n",
        "all_files = glob.glob(\"drive/My Drive/kaggle_ddsm/low_res_200_200/*.png\")\n",
        "# print(all_files)\n",
        "labels = np.zeros(len(all_files), dtype=np.float)\n",
        "for i in range(len(all_files)):\n",
        "    files = all_files[i].split('/')[4]\n",
        "    # print(files)\n",
        "    labels[i] = int(files.split('_')[4])\n",
        "print(labels)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. ... 0. 1. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfUPc_gkqqX-",
        "outputId": "7a9a9a1d-18bf-4288-bc0b-c2f2dca580fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "''' Read images '''\n",
        "dataset = []\n",
        "for i in range(len(all_files)):\n",
        "    # image = plt.imread(all_files[i])\n",
        "    image = cv2.imread(all_files[i], cv2.IMREAD_GRAYSCALE)\n",
        "    ''' Normalize images '''\n",
        "    # image = image.astype('float32')\n",
        "    # image /= np.float(np.max(image))\n",
        "    dataset.append(image)\n",
        "dataset = np.array(dataset, dtype=np.float)\n",
        "print(dataset.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11177, 120, 120)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7AtzyaIpBoh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Z1ZgXhwhvC6",
        "outputId": "843c2755-8be7-44ae-af8f-fb80784e05bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        }
      },
      "source": [
        "''' Equalize dataset malignant and benign labels '''\n",
        "dataset, labels = dataset_equalizer(dataset, labels)\n",
        "print(dataset.shape)\n",
        "print(labels.shape)\n",
        "print(labels)\n",
        "\n",
        "''' Normalize images '''\n",
        "##################################\n",
        "# Normalization task is done in reading part\n",
        "##################################\n",
        "print('Normalization')\n",
        "dataset = dataset.astype('float32')\n",
        "print(np.max(dataset))\n",
        "print(np.min(dataset))\n",
        "dataset /= np.float(255)\n",
        "print(np.max(dataset))\n",
        "print(np.min(dataset))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2958, 120, 120)\n",
            "(2958,)\n",
            "[0. 0. 1. ... 1. 1. 0.]\n",
            "Normalization\n",
            "255.0\n",
            "0.0\n",
            "1.0\n",
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mj2nBij1hvOa"
      },
      "source": [
        "''' Image channels compatible with the network '''\n",
        "# 3 Channel image:\n",
        "dataset = np.stack((dataset,) * 3, axis=-1)\n",
        "x_train_1, x_test_1, y_train1, y_test1 = train_test_split(dataset, labels, test_size=0.001)  # , shuffle=True)\n",
        "# x_train_1 = dataset\n",
        "# y_train1 = labels\n",
        "\n",
        "''' Categorical labels '''\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "y_train1 = to_categorical(y_train1, num_classes=len(np.unique(labels)))\n",
        "y_test1 = to_categorical(y_test1, num_classes=len(np.unique(labels)))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txP11zpxmoVc",
        "outputId": "5e6fe5c5-da92-416b-d91a-78da0cd81540",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "''' Efficient Net codes: '''\n",
        "\n",
        "print(dataset.shape)\n",
        "# print(y_train1)\n",
        "\n",
        "''' Define Swish activation function '''\n",
        "# Swish definition\n",
        "from keras.backend import sigmoid\n",
        "\n",
        "\n",
        "class SwishActivation(Activation):\n",
        "\n",
        "    def __init__(self, activation, **kwargs):\n",
        "        super(SwishActivation, self).__init__(activation, **kwargs)\n",
        "        self.__name__ = 'swish_act'\n",
        "\n",
        "\n",
        "def swish_act(x, beta=1):\n",
        "    return (x * sigmoid(beta * x))\n",
        "\n",
        "\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "from keras.layers import Activation\n",
        "\n",
        "get_custom_objects().update({'swish_act': SwishActivation(swish_act)})\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2958, 120, 120, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gw-GS-PRmsWK",
        "outputId": "6fddb8cc-bd44-4e3f-b1d5-28ba6cb33bff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "''' Initialization '''\n",
        "# x_train_1 = x_train_1[..., np.newaxis]\n",
        "# # x_train_2 = x_train_2[..., np.newaxis]\n",
        "# x_test_1 = x_test_1[..., np.newaxis]\n",
        "# # x_test_2 = x_test_2[..., np.newaxis]\n",
        "# print(y_train1.shape)\n",
        "# print(y_test1.shape)\n",
        "input_shape = x_train_1.shape[1:]\n",
        "print(input_shape)\n",
        "\n",
        "# loading B0 pre-trained on ImageNet without final aka fiature extractor\n",
        "model = enet.EfficientNetB0(include_top=False, pooling='avg', input_shape=(120, 120, 3), weights='imagenet')\n",
        "\n",
        "# # building 2 fully connected layer\n",
        "x = model.output\n",
        "\n",
        "# x = BatchNormalization()(x)\n",
        "# x = Dropout(0.2)(x)\n",
        "#\n",
        "# x = Dense(512)(x)\n",
        "# x = BatchNormalization()(x)\n",
        "# x = Activation(swish_act)(x)\n",
        "# x = Dropout(0.2)(x)\n",
        "#\n",
        "# x = Dense(128)(x)\n",
        "# x = BatchNormalization()(x)\n",
        "# x = Activation(swish_act)(x)\n",
        "\n",
        "# output layer\n",
        "predictions = Dense(2, activation=\"softmax\")(x)\n",
        "\n",
        "model_final = Model(inputs=model.input, outputs=predictions)\n",
        "\n",
        "model_final.summary()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(120, 120, 3)\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 120, 120, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "stem_conv (Conv2D)              (None, 60, 60, 32)   864         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "stem_bn (BatchNormalization)    (None, 60, 60, 32)   128         stem_conv[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "stem_activation (Activation)    (None, 60, 60, 32)   0           stem_bn[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block1a_dwconv (DepthwiseConv2D (None, 60, 60, 32)   288         stem_activation[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block1a_bn (BatchNormalization) (None, 60, 60, 32)   128         block1a_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block1a_activation (Activation) (None, 60, 60, 32)   0           block1a_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block1a_se_squeeze (GlobalAvera (None, 32)           0           block1a_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block1a_se_reshape (Reshape)    (None, 1, 1, 32)     0           block1a_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block1a_se_reduce (Conv2D)      (None, 1, 1, 8)      264         block1a_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block1a_se_expand (Conv2D)      (None, 1, 1, 32)     288         block1a_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block1a_se_excite (Multiply)    (None, 60, 60, 32)   0           block1a_activation[0][0]         \n",
            "                                                                 block1a_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block1a_project_conv (Conv2D)   (None, 60, 60, 16)   512         block1a_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block1a_project_bn (BatchNormal (None, 60, 60, 16)   64          block1a_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block2a_expand_conv (Conv2D)    (None, 60, 60, 96)   1536        block1a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2a_expand_bn (BatchNormali (None, 60, 60, 96)   384         block2a_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block2a_expand_activation (Acti (None, 60, 60, 96)   0           block2a_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2a_dwconv (DepthwiseConv2D (None, 30, 30, 96)   864         block2a_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block2a_bn (BatchNormalization) (None, 30, 30, 96)   384         block2a_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block2a_activation (Activation) (None, 30, 30, 96)   0           block2a_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block2a_se_squeeze (GlobalAvera (None, 96)           0           block2a_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2a_se_reshape (Reshape)    (None, 1, 1, 96)     0           block2a_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2a_se_reduce (Conv2D)      (None, 1, 1, 4)      388         block2a_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2a_se_expand (Conv2D)      (None, 1, 1, 96)     480         block2a_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2a_se_excite (Multiply)    (None, 30, 30, 96)   0           block2a_activation[0][0]         \n",
            "                                                                 block2a_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2a_project_conv (Conv2D)   (None, 30, 30, 24)   2304        block2a_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2a_project_bn (BatchNormal (None, 30, 30, 24)   96          block2a_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block2b_expand_conv (Conv2D)    (None, 30, 30, 144)  3456        block2a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2b_expand_bn (BatchNormali (None, 30, 30, 144)  576         block2b_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block2b_expand_activation (Acti (None, 30, 30, 144)  0           block2b_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2b_dwconv (DepthwiseConv2D (None, 30, 30, 144)  1296        block2b_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block2b_bn (BatchNormalization) (None, 30, 30, 144)  576         block2b_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block2b_activation (Activation) (None, 30, 30, 144)  0           block2b_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block2b_se_squeeze (GlobalAvera (None, 144)          0           block2b_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2b_se_reshape (Reshape)    (None, 1, 1, 144)    0           block2b_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2b_se_reduce (Conv2D)      (None, 1, 1, 6)      870         block2b_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2b_se_expand (Conv2D)      (None, 1, 1, 144)    1008        block2b_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2b_se_excite (Multiply)    (None, 30, 30, 144)  0           block2b_activation[0][0]         \n",
            "                                                                 block2b_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2b_project_conv (Conv2D)   (None, 30, 30, 24)   3456        block2b_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block2b_project_bn (BatchNormal (None, 30, 30, 24)   96          block2b_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block2b_drop (FixedDropout)     (None, 30, 30, 24)   0           block2b_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2b_add (Add)               (None, 30, 30, 24)   0           block2b_drop[0][0]               \n",
            "                                                                 block2a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3a_expand_conv (Conv2D)    (None, 30, 30, 144)  3456        block2b_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block3a_expand_bn (BatchNormali (None, 30, 30, 144)  576         block3a_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3a_expand_activation (Acti (None, 30, 30, 144)  0           block3a_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3a_dwconv (DepthwiseConv2D (None, 15, 15, 144)  3600        block3a_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block3a_bn (BatchNormalization) (None, 15, 15, 144)  576         block3a_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block3a_activation (Activation) (None, 15, 15, 144)  0           block3a_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block3a_se_squeeze (GlobalAvera (None, 144)          0           block3a_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3a_se_reshape (Reshape)    (None, 1, 1, 144)    0           block3a_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3a_se_reduce (Conv2D)      (None, 1, 1, 6)      870         block3a_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3a_se_expand (Conv2D)      (None, 1, 1, 144)    1008        block3a_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3a_se_excite (Multiply)    (None, 15, 15, 144)  0           block3a_activation[0][0]         \n",
            "                                                                 block3a_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3a_project_conv (Conv2D)   (None, 15, 15, 40)   5760        block3a_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3a_project_bn (BatchNormal (None, 15, 15, 40)   160         block3a_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block3b_expand_conv (Conv2D)    (None, 15, 15, 240)  9600        block3a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3b_expand_bn (BatchNormali (None, 15, 15, 240)  960         block3b_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3b_expand_activation (Acti (None, 15, 15, 240)  0           block3b_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3b_dwconv (DepthwiseConv2D (None, 15, 15, 240)  6000        block3b_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block3b_bn (BatchNormalization) (None, 15, 15, 240)  960         block3b_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block3b_activation (Activation) (None, 15, 15, 240)  0           block3b_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block3b_se_squeeze (GlobalAvera (None, 240)          0           block3b_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3b_se_reshape (Reshape)    (None, 1, 1, 240)    0           block3b_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3b_se_reduce (Conv2D)      (None, 1, 1, 10)     2410        block3b_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3b_se_expand (Conv2D)      (None, 1, 1, 240)    2640        block3b_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3b_se_excite (Multiply)    (None, 15, 15, 240)  0           block3b_activation[0][0]         \n",
            "                                                                 block3b_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3b_project_conv (Conv2D)   (None, 15, 15, 40)   9600        block3b_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block3b_project_bn (BatchNormal (None, 15, 15, 40)   160         block3b_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block3b_drop (FixedDropout)     (None, 15, 15, 40)   0           block3b_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3b_add (Add)               (None, 15, 15, 40)   0           block3b_drop[0][0]               \n",
            "                                                                 block3a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4a_expand_conv (Conv2D)    (None, 15, 15, 240)  9600        block3b_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4a_expand_bn (BatchNormali (None, 15, 15, 240)  960         block4a_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4a_expand_activation (Acti (None, 15, 15, 240)  0           block4a_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4a_dwconv (DepthwiseConv2D (None, 8, 8, 240)    2160        block4a_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block4a_bn (BatchNormalization) (None, 8, 8, 240)    960         block4a_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block4a_activation (Activation) (None, 8, 8, 240)    0           block4a_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block4a_se_squeeze (GlobalAvera (None, 240)          0           block4a_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4a_se_reshape (Reshape)    (None, 1, 1, 240)    0           block4a_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4a_se_reduce (Conv2D)      (None, 1, 1, 10)     2410        block4a_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4a_se_expand (Conv2D)      (None, 1, 1, 240)    2640        block4a_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4a_se_excite (Multiply)    (None, 8, 8, 240)    0           block4a_activation[0][0]         \n",
            "                                                                 block4a_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4a_project_conv (Conv2D)   (None, 8, 8, 80)     19200       block4a_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4a_project_bn (BatchNormal (None, 8, 8, 80)     320         block4a_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block4b_expand_conv (Conv2D)    (None, 8, 8, 480)    38400       block4a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4b_expand_bn (BatchNormali (None, 8, 8, 480)    1920        block4b_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4b_expand_activation (Acti (None, 8, 8, 480)    0           block4b_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4b_dwconv (DepthwiseConv2D (None, 8, 8, 480)    4320        block4b_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block4b_bn (BatchNormalization) (None, 8, 8, 480)    1920        block4b_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block4b_activation (Activation) (None, 8, 8, 480)    0           block4b_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block4b_se_squeeze (GlobalAvera (None, 480)          0           block4b_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4b_se_reshape (Reshape)    (None, 1, 1, 480)    0           block4b_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4b_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block4b_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4b_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block4b_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4b_se_excite (Multiply)    (None, 8, 8, 480)    0           block4b_activation[0][0]         \n",
            "                                                                 block4b_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4b_project_conv (Conv2D)   (None, 8, 8, 80)     38400       block4b_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4b_project_bn (BatchNormal (None, 8, 8, 80)     320         block4b_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block4b_drop (FixedDropout)     (None, 8, 8, 80)     0           block4b_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4b_add (Add)               (None, 8, 8, 80)     0           block4b_drop[0][0]               \n",
            "                                                                 block4a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4c_expand_conv (Conv2D)    (None, 8, 8, 480)    38400       block4b_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4c_expand_bn (BatchNormali (None, 8, 8, 480)    1920        block4c_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4c_expand_activation (Acti (None, 8, 8, 480)    0           block4c_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4c_dwconv (DepthwiseConv2D (None, 8, 8, 480)    4320        block4c_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block4c_bn (BatchNormalization) (None, 8, 8, 480)    1920        block4c_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block4c_activation (Activation) (None, 8, 8, 480)    0           block4c_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block4c_se_squeeze (GlobalAvera (None, 480)          0           block4c_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4c_se_reshape (Reshape)    (None, 1, 1, 480)    0           block4c_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4c_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block4c_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4c_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block4c_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4c_se_excite (Multiply)    (None, 8, 8, 480)    0           block4c_activation[0][0]         \n",
            "                                                                 block4c_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4c_project_conv (Conv2D)   (None, 8, 8, 80)     38400       block4c_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block4c_project_bn (BatchNormal (None, 8, 8, 80)     320         block4c_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block4c_drop (FixedDropout)     (None, 8, 8, 80)     0           block4c_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4c_add (Add)               (None, 8, 8, 80)     0           block4c_drop[0][0]               \n",
            "                                                                 block4b_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5a_expand_conv (Conv2D)    (None, 8, 8, 480)    38400       block4c_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5a_expand_bn (BatchNormali (None, 8, 8, 480)    1920        block5a_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5a_expand_activation (Acti (None, 8, 8, 480)    0           block5a_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5a_dwconv (DepthwiseConv2D (None, 8, 8, 480)    12000       block5a_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block5a_bn (BatchNormalization) (None, 8, 8, 480)    1920        block5a_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block5a_activation (Activation) (None, 8, 8, 480)    0           block5a_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block5a_se_squeeze (GlobalAvera (None, 480)          0           block5a_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5a_se_reshape (Reshape)    (None, 1, 1, 480)    0           block5a_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5a_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block5a_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5a_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block5a_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5a_se_excite (Multiply)    (None, 8, 8, 480)    0           block5a_activation[0][0]         \n",
            "                                                                 block5a_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5a_project_conv (Conv2D)   (None, 8, 8, 112)    53760       block5a_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5a_project_bn (BatchNormal (None, 8, 8, 112)    448         block5a_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block5b_expand_conv (Conv2D)    (None, 8, 8, 672)    75264       block5a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5b_expand_bn (BatchNormali (None, 8, 8, 672)    2688        block5b_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5b_expand_activation (Acti (None, 8, 8, 672)    0           block5b_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5b_dwconv (DepthwiseConv2D (None, 8, 8, 672)    16800       block5b_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block5b_bn (BatchNormalization) (None, 8, 8, 672)    2688        block5b_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block5b_activation (Activation) (None, 8, 8, 672)    0           block5b_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block5b_se_squeeze (GlobalAvera (None, 672)          0           block5b_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5b_se_reshape (Reshape)    (None, 1, 1, 672)    0           block5b_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5b_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block5b_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5b_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block5b_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5b_se_excite (Multiply)    (None, 8, 8, 672)    0           block5b_activation[0][0]         \n",
            "                                                                 block5b_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5b_project_conv (Conv2D)   (None, 8, 8, 112)    75264       block5b_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5b_project_bn (BatchNormal (None, 8, 8, 112)    448         block5b_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block5b_drop (FixedDropout)     (None, 8, 8, 112)    0           block5b_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5b_add (Add)               (None, 8, 8, 112)    0           block5b_drop[0][0]               \n",
            "                                                                 block5a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5c_expand_conv (Conv2D)    (None, 8, 8, 672)    75264       block5b_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5c_expand_bn (BatchNormali (None, 8, 8, 672)    2688        block5c_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5c_expand_activation (Acti (None, 8, 8, 672)    0           block5c_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5c_dwconv (DepthwiseConv2D (None, 8, 8, 672)    16800       block5c_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block5c_bn (BatchNormalization) (None, 8, 8, 672)    2688        block5c_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block5c_activation (Activation) (None, 8, 8, 672)    0           block5c_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block5c_se_squeeze (GlobalAvera (None, 672)          0           block5c_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5c_se_reshape (Reshape)    (None, 1, 1, 672)    0           block5c_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5c_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block5c_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5c_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block5c_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5c_se_excite (Multiply)    (None, 8, 8, 672)    0           block5c_activation[0][0]         \n",
            "                                                                 block5c_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5c_project_conv (Conv2D)   (None, 8, 8, 112)    75264       block5c_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block5c_project_bn (BatchNormal (None, 8, 8, 112)    448         block5c_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block5c_drop (FixedDropout)     (None, 8, 8, 112)    0           block5c_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5c_add (Add)               (None, 8, 8, 112)    0           block5c_drop[0][0]               \n",
            "                                                                 block5b_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block6a_expand_conv (Conv2D)    (None, 8, 8, 672)    75264       block5c_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block6a_expand_bn (BatchNormali (None, 8, 8, 672)    2688        block6a_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6a_expand_activation (Acti (None, 8, 8, 672)    0           block6a_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6a_dwconv (DepthwiseConv2D (None, 4, 4, 672)    16800       block6a_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block6a_bn (BatchNormalization) (None, 4, 4, 672)    2688        block6a_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block6a_activation (Activation) (None, 4, 4, 672)    0           block6a_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block6a_se_squeeze (GlobalAvera (None, 672)          0           block6a_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6a_se_reshape (Reshape)    (None, 1, 1, 672)    0           block6a_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6a_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block6a_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6a_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block6a_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6a_se_excite (Multiply)    (None, 4, 4, 672)    0           block6a_activation[0][0]         \n",
            "                                                                 block6a_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6a_project_conv (Conv2D)   (None, 4, 4, 192)    129024      block6a_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6a_project_bn (BatchNormal (None, 4, 4, 192)    768         block6a_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block6b_expand_conv (Conv2D)    (None, 4, 4, 1152)   221184      block6a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6b_expand_bn (BatchNormali (None, 4, 4, 1152)   4608        block6b_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6b_expand_activation (Acti (None, 4, 4, 1152)   0           block6b_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6b_dwconv (DepthwiseConv2D (None, 4, 4, 1152)   28800       block6b_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block6b_bn (BatchNormalization) (None, 4, 4, 1152)   4608        block6b_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block6b_activation (Activation) (None, 4, 4, 1152)   0           block6b_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block6b_se_squeeze (GlobalAvera (None, 1152)         0           block6b_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6b_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block6b_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6b_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block6b_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6b_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block6b_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6b_se_excite (Multiply)    (None, 4, 4, 1152)   0           block6b_activation[0][0]         \n",
            "                                                                 block6b_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6b_project_conv (Conv2D)   (None, 4, 4, 192)    221184      block6b_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6b_project_bn (BatchNormal (None, 4, 4, 192)    768         block6b_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block6b_drop (FixedDropout)     (None, 4, 4, 192)    0           block6b_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6b_add (Add)               (None, 4, 4, 192)    0           block6b_drop[0][0]               \n",
            "                                                                 block6a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6c_expand_conv (Conv2D)    (None, 4, 4, 1152)   221184      block6b_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block6c_expand_bn (BatchNormali (None, 4, 4, 1152)   4608        block6c_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6c_expand_activation (Acti (None, 4, 4, 1152)   0           block6c_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6c_dwconv (DepthwiseConv2D (None, 4, 4, 1152)   28800       block6c_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block6c_bn (BatchNormalization) (None, 4, 4, 1152)   4608        block6c_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block6c_activation (Activation) (None, 4, 4, 1152)   0           block6c_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block6c_se_squeeze (GlobalAvera (None, 1152)         0           block6c_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6c_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block6c_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6c_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block6c_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6c_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block6c_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6c_se_excite (Multiply)    (None, 4, 4, 1152)   0           block6c_activation[0][0]         \n",
            "                                                                 block6c_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6c_project_conv (Conv2D)   (None, 4, 4, 192)    221184      block6c_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6c_project_bn (BatchNormal (None, 4, 4, 192)    768         block6c_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block6c_drop (FixedDropout)     (None, 4, 4, 192)    0           block6c_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6c_add (Add)               (None, 4, 4, 192)    0           block6c_drop[0][0]               \n",
            "                                                                 block6b_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block6d_expand_conv (Conv2D)    (None, 4, 4, 1152)   221184      block6c_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block6d_expand_bn (BatchNormali (None, 4, 4, 1152)   4608        block6d_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6d_expand_activation (Acti (None, 4, 4, 1152)   0           block6d_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6d_dwconv (DepthwiseConv2D (None, 4, 4, 1152)   28800       block6d_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block6d_bn (BatchNormalization) (None, 4, 4, 1152)   4608        block6d_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block6d_activation (Activation) (None, 4, 4, 1152)   0           block6d_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block6d_se_squeeze (GlobalAvera (None, 1152)         0           block6d_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6d_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block6d_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6d_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block6d_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6d_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block6d_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6d_se_excite (Multiply)    (None, 4, 4, 1152)   0           block6d_activation[0][0]         \n",
            "                                                                 block6d_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6d_project_conv (Conv2D)   (None, 4, 4, 192)    221184      block6d_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block6d_project_bn (BatchNormal (None, 4, 4, 192)    768         block6d_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block6d_drop (FixedDropout)     (None, 4, 4, 192)    0           block6d_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6d_add (Add)               (None, 4, 4, 192)    0           block6d_drop[0][0]               \n",
            "                                                                 block6c_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block7a_expand_conv (Conv2D)    (None, 4, 4, 1152)   221184      block6d_add[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block7a_expand_bn (BatchNormali (None, 4, 4, 1152)   4608        block7a_expand_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7a_expand_activation (Acti (None, 4, 4, 1152)   0           block7a_expand_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block7a_dwconv (DepthwiseConv2D (None, 4, 4, 1152)   10368       block7a_expand_activation[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "block7a_bn (BatchNormalization) (None, 4, 4, 1152)   4608        block7a_dwconv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block7a_activation (Activation) (None, 4, 4, 1152)   0           block7a_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "block7a_se_squeeze (GlobalAvera (None, 1152)         0           block7a_activation[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7a_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block7a_se_squeeze[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7a_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block7a_se_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7a_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block7a_se_reduce[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block7a_se_excite (Multiply)    (None, 4, 4, 1152)   0           block7a_activation[0][0]         \n",
            "                                                                 block7a_se_expand[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block7a_project_conv (Conv2D)   (None, 4, 4, 320)    368640      block7a_se_excite[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "block7a_project_bn (BatchNormal (None, 4, 4, 320)    1280        block7a_project_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "top_conv (Conv2D)               (None, 4, 4, 1280)   409600      block7a_project_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "top_bn (BatchNormalization)     (None, 4, 4, 1280)   5120        top_conv[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "top_activation (Activation)     (None, 4, 4, 1280)   0           top_bn[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (GlobalAveragePooling2 (None, 1280)         0           top_activation[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 2)            2562        avg_pool[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 4,052,126\n",
            "Trainable params: 4,010,110\n",
            "Non-trainable params: 42,016\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hv3ZehZGmwRq",
        "outputId": "7638541f-4536-4de6-eeda-2d9432e865ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "''' Depict model '''\n",
        "# model_final.summary()\n",
        "# from keras.utils import plot_model\n",
        "# import matplotlib.pyplot as plt\n",
        "# import os\n",
        "# import cv2\n",
        "#\n",
        "# os.environ[\"PATH\"] += os.pathsep + 'D:\\\\university\\\\term_4\\\\my_libs\\\\release\\\\bin'\n",
        "# plot_model(model_final, to_file='model_single.png', show_shapes=True, show_layer_names=False)\n",
        "# image = cv2.imread('model_single.png')\n",
        "# plt.imshow(image)\n",
        "# plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "' Depict model '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhsNR98FmyeR"
      },
      "source": [
        "''' Plot online results (Live results)'''\n",
        "from IPython.display import clear_output\n",
        "\n",
        "\n",
        "class PlotLosses(keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.i = 0\n",
        "        self.x = []\n",
        "        self.losses = []\n",
        "        self.val_losses = []\n",
        "        self.acces = []\n",
        "        self.val_acces = []\n",
        "\n",
        "        self.fig = plt.figure()\n",
        "\n",
        "        self.logs = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.logs.append(logs)\n",
        "        self.x.append(self.i)\n",
        "        self.losses.append(logs.get('loss'))\n",
        "        self.val_losses.append(logs.get('val_loss'))\n",
        "        self.acces.append(logs.get('acc'))\n",
        "        self.val_acces.append(logs.get('val_acc'))\n",
        "        self.i += 1\n",
        "\n",
        "        clear_output(wait=True)\n",
        "        plt.plot(self.x, self.losses, label=\"loss\")\n",
        "        plt.plot(self.x, self.val_losses, label=\"val_loss\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "\n",
        "        ''' Validation Accuracy plot '''\n",
        "        # plt.plot(self.x, self.acces, label=\"acc\")\n",
        "        # plt.plot(self.x, self.val_acces, label=\"val_acc\")\n",
        "        # plt.legend()\n",
        "        # plt.grid(True)\n",
        "        # plt.show()\n",
        "\n",
        "\n",
        "plot_losses = PlotLosses()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZEzQQdh76xQ"
      },
      "source": [
        "# !pip install adabound-keras\n",
        "from keras.optimizers import Optimizer\n",
        "from keras.legacy import interfaces\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "class AdaBound_class(Optimizer):\n",
        "    def __init__(self, lr=0.001,\n",
        "                 beta_1=0.9, beta_2=0.999,\n",
        "                 gamma=0.001,\n",
        "                 final_lr=0.1,\n",
        "                 epsilon=None,\n",
        "                 decay=0.,\n",
        "                 amsbound=False,\n",
        "                 **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        with K.name_scope(self.__class__.__name__):\n",
        "            self.iterations = K.variable(0, dtype='int64', name='iterations')\n",
        "            self.lr = K.variable(lr, name='lr')\n",
        "            self.beta_1 = K.variable(beta_1, name='beta_1')\n",
        "            self.beta_2 = K.variable(beta_1, name='beta_2')\n",
        "            self.gamma = K.variable(gamma, name='gamma')\n",
        "            self.final_lr = K.variable(final_lr, name='final_lr')\n",
        "            self.decay = K.variable(decay, name='decay')\n",
        "        if epsilon is None:\n",
        "            epsilon = K.epsilon()\n",
        "        self.epsilon = epsilon\n",
        "        self.initial_decay = decay\n",
        "        self.amsbound = amsbound\n",
        "\n",
        "    @interfaces.legacy_get_updates_support\n",
        "    def get_updates(self, loss, params):\n",
        "        grads = self.get_gradients(loss, params)\n",
        "        self.updates = [K.update_add(self.iterations, 1)]\n",
        "\n",
        "        lr = self.lr\n",
        "        if self.initial_decay > 0:\n",
        "            lr = lr * (1. / (1. + self.decay * K.cast(self.iterations,\n",
        "                                                      K.dtype(self.decay))))\n",
        "\n",
        "        t = K.cast(self.iterations, K.floatx()) + 1\n",
        "        lr_t = lr * (K.sqrt(1. - K.pow(self.beta_2, t)) /\n",
        "                     (1. - K.pow(self.beta_1, t)))\n",
        "\n",
        "        ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
        "        vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
        "\n",
        "        if self.amsbound:\n",
        "            vhats = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
        "        else:\n",
        "            vhats = [K.zeros((1, 1)) for _ in params]\n",
        "\n",
        "        self.weights = [self.iterations] + ms + vs + vhats\n",
        "\n",
        "        for p, g, m, v, vhat in zip(params, grads, ms, vs, vhats):\n",
        "            m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n",
        "            v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(g)\n",
        "            lower_bound_t = self.final_lr * (1 - 1 / self.gamma * t + 1)\n",
        "            upper_bound_t = self.final_lr * (1 + 1 / self.gamma * t)\n",
        "\n",
        "            if self.amsbound:\n",
        "                vhat_t = K.maximum(vhat, v_t)\n",
        "                # p_t = p - K.clip(lr_t * (K.sqrt(vhat_t) + self.epsilon),\n",
        "                #                  lower_bound_t,\n",
        "                #                  upper_bound_t)\n",
        "                p_t = p - tf.clip_by_value(\n",
        "                    lr_t * (K.sqrt(vhat_t) + self.epsilon),\n",
        "                    lower_bound_t,\n",
        "                    upper_bound_t)\n",
        "            else:\n",
        "                # p_t = p - K.clip(lr_t * (K.sqrt(v_t) + self.epsilon),\n",
        "                #                  lower_bound_t,\n",
        "                #                  upper_bound_t)\n",
        "                p_t = p - tf.clip_by_value(\n",
        "                    lr_t * (K.sqrt(v_t) + self.epsilon),\n",
        "                    lower_bound_t,\n",
        "                    upper_bound_t)\n",
        "\n",
        "            self.updates.append(K.update(m, m_t))\n",
        "            self.updates.append(K.update(v, v_t))\n",
        "            new_p = p_t\n",
        "\n",
        "            # Apply constraints.\n",
        "            if getattr(p, 'constraint', None) is not None:\n",
        "                new_p = p.constraint(new_p)\n",
        "\n",
        "            self.updates.append(K.update(p, new_p))\n",
        "\n",
        "        return self.updates\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {'lr': float(K.get_value(self.lr)),\n",
        "                  'beta_1': float(K.get_value(self.beta_1)),\n",
        "                  'beta_2': float(K.get_value(self.beta_2)),\n",
        "                  'gamma': float(K.get_value(self.gamma)),\n",
        "                  'final_lr': float(K.get_value(self.final_lr)),\n",
        "                  'decay': float(K.get_value(self.decay)),\n",
        "                  'epsilon': self.epsilon,\n",
        "                  'amsbound': self.amsbound}\n",
        "        base_config = super().get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2n4kEnJ8Hvc3"
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "from tensorflow.python.keras import backend as K\n",
        "from tensorflow.python.keras.optimizers import Optimizer\n",
        "from tensorflow.python.ops import state_ops\n",
        "from tensorflow.python.ops import math_ops\n",
        "\n",
        "\n",
        "class AdaBound1(Optimizer):\n",
        "    \"\"\"AdaBound optimizer.\n",
        "    Default parameters follow those provided in the original paper.\n",
        "    Arguments:\n",
        "        lr: float >= 0. Learning rate.\n",
        "        beta_1: float, 0 < beta < 1. Generally close to 1.\n",
        "        beta_2: float, 0 < beta < 1. Generally close to 1.\n",
        "        final_lr: float >= 0. Final learning rate.\n",
        "        gamma: float >= 0. Convergence speed of the bound functions.\n",
        "        epsilon: float >= 0. Fuzz factor. If `None`, defaults to `K.epsilon()`.\n",
        "        decay: float >= 0. Learning rate decay over each update.\n",
        "        amsbound: boolean. Whether to use the AMSBound variant of this algorithm\n",
        "            from the paper \"Adaptive Gradient Methods with Dynamic Bound of Learning Rate\".\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 lr=0.001,\n",
        "                 beta_1=0.9,\n",
        "                 beta_2=0.999,\n",
        "                 final_lr=0.1,\n",
        "                 gamma=0.001,\n",
        "                 epsilon=1e-8,\n",
        "                 decay=0.,\n",
        "                 amsbound=False,\n",
        "                 **kwargs):\n",
        "        super(AdaBound, self).all(**kwargs)#.__init__(**kwargs)\n",
        "        with K.name_scope(self.__class__.__name__):\n",
        "            self.iterations = K.variable(0, dtype='int64', name='iterations')\n",
        "            self.lr = K.variable(lr, name='lr')\n",
        "            self.beta_1 = K.variable(beta_1, name='beta_1')\n",
        "            self.beta_2 = K.variable(beta_2, name='beta_2')\n",
        "            self.final_lr = K.variable(final_lr, name='final_lr')\n",
        "            self.gamma = K.variable(gamma, name='gamma')\n",
        "            self.decay = K.variable(decay, name='decay')\n",
        "            self.amsbound = K.variable(amsbound, name='amsbound')\n",
        "        if epsilon is None:\n",
        "            epsilon = K.epsilon()\n",
        "        self.epsilon = K.variable(epsilon)\n",
        "        self.initial_decay = decay\n",
        "        self.base_lr = lr\n",
        "\n",
        "    def get_updates(self, loss, params):\n",
        "        grads = self.get_gradients(loss, params)\n",
        "        self.updates = [state_ops.assign_add(self.iterations, 1)]\n",
        "\n",
        "        lr = self.lr\n",
        "        if self.initial_decay > 0:\n",
        "            lr = lr * (\n",
        "                    1. / (1. + self.decay * math_ops.cast(self.iterations,\n",
        "                                                          K.dtype(self.decay))))\n",
        "\n",
        "        t = math_ops.cast(self.iterations, K.floatx()) + 1\n",
        "        lr_t = lr * (\n",
        "                K.sqrt(1. - math_ops.pow(self.beta_2, t)) /\n",
        "                (1. - math_ops.pow(self.beta_1, t)))\n",
        "\n",
        "        final_lr = self.final_lr * lr / self.base_lr\n",
        "        lower_bound = final_lr * (1. - 1. / (self.gamma * t + 1))\n",
        "        upper_bound = final_lr * (1. + 1. / (self.gamma * t))\n",
        "\n",
        "        ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
        "        vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
        "        if self.amsbound:\n",
        "            vhats = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
        "        else:\n",
        "            vhats = [K.zeros(1) for _ in params]\n",
        "        self.weights = [self.iterations] + ms + vs + vhats\n",
        "\n",
        "        for p, g, m, v, vhat in zip(params, grads, ms, vs, vhats):\n",
        "            m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n",
        "            v_t = (self.beta_2 * v) + (1. - self.beta_2) * math_ops.square(g)\n",
        "            if self.amsbound:\n",
        "                vhat_t = math_ops.maximum(vhat, v_t)\n",
        "                p_t = p - m_t * K.clip(lr_t / (K.sqrt(vhat_t) + self.epsilon), lower_bound, upper_bound)\n",
        "                self.updates.append(state_ops.assign(vhat, vhat_t))\n",
        "            else:\n",
        "                p_t = p - m_t * K.clip(lr_t / (K.sqrt(v_t) + self.epsilon), lower_bound, upper_bound)\n",
        "\n",
        "            self.updates.append(state_ops.assign(m, m_t))\n",
        "            self.updates.append(state_ops.assign(v, v_t))\n",
        "            new_p = p_t\n",
        "\n",
        "            # Apply constraints.\n",
        "            if getattr(p, 'constraint', None) is not None:\n",
        "                new_p = p.constraint(new_p)\n",
        "\n",
        "            self.updates.append(state_ops.assign(p, new_p))\n",
        "        return self.updates\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'lr': float(K.get_value(self.lr)),\n",
        "            'beta1': float(K.get_value(self.beta_1)),\n",
        "            'beta2': float(K.get_value(self.beta_2)),\n",
        "            'final_lr': float(K.get_value(self.final_lr)),\n",
        "            'gamma': float(K.get_value(self.gamma)),\n",
        "            'decay': float(K.get_value(self.decay)),\n",
        "            'epsilon': self.epsilon,\n",
        "            'amsbound': self.amsbound\n",
        "        }\n",
        "        base_config = super(AdaBound, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfFZ4DDgm1mj",
        "outputId": "3d2d03d9-d181-4f59-f386-080ac85d9bd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        }
      },
      "source": [
        "''' Train model '''\n",
        "# model compilation\n",
        "# Memory check\n",
        "# import tensorflow as tf\n",
        "# from keras.backend.tensorflow_backend import set_session\n",
        "# config = tf.ConfigProto()\n",
        "# config.gpu_options.allow_growth = True\n",
        "# config.log_device_placement = True\n",
        "# sess = tf.Session(config=config)\n",
        "# set_session(sess)\n",
        "# from keras_adabound import AdaBound\n",
        "# from adabound_keras.adabound import AdaBound\n",
        "\n",
        "# from adabound import AdaBound\n",
        "# import adabound\n",
        "\n",
        "sgd = SGD(lr=0.0007, decay=1e-6, momentum=0.8, nesterov=False)\n",
        "# optm = adabound.AdaBound(model.parameters(), lr=1e-3, final_lr=0.1)\n",
        "\n",
        "# optm = AdaBound(lr=1e-03,\n",
        "#                 final_lr=0.1,\n",
        "#                 gamma=1e-03,\n",
        "#                 weight_decay=0.,\n",
        "#                 # amsbound=False,\n",
        "#                 )\n",
        "\n",
        "# optm = AdaBound(lr=8*1e-04,\n",
        "#                 # param=None,\n",
        "#                 final_lr=0.1,\n",
        "#                 gamma=1e-03)\n",
        "\n",
        "a = AdaBound1()\n",
        "optm = a(lr=0.001, beta1=0.9, beta2=0.999, final_lr=0.1, gamma=1e-3, epsilon=None, weight_decay=0, amsbound=False)\n",
        "\n",
        "run_opts = tf.RunOptions(report_tensor_allocations_upon_oom=True)\n",
        "model_final.compile(loss='binary_crossentropy',\n",
        "                    optimizer=optm,\n",
        "                    metrics=['accuracy'])\n",
        "\n",
        "mcp_save = ModelCheckpoint('EnetB0_CIFAR10_TL.h5', save_best_only=True, monitor='val_accuracy')\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=2, verbose=1, )\n",
        "\n",
        "# print(\"Training....\")\n",
        "history = model_final.fit(x_train_1, y_train1,\n",
        "                          batch_size=16,\n",
        "                          epochs=30,\n",
        "                          validation_split=0.1,\n",
        "                          callbacks=[plot_losses, mcp_save, reduce_lr],\n",
        "                          # shuffle=True,\n",
        "                          verbose=1)\n",
        "# history = model.fit(x_train_1, y_train1,\n",
        "#                     validation_data=(x_test_1, y_test1),\n",
        "#                     callbacks=[plot_losses],\n",
        "#                     epochs=10, batch_size=4, shuffle=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-ac2a19f6d408>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m#                 gamma=1e-03)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdaBound1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0moptm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.999\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamsbound\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-42-adb724af12c7>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, lr, beta_1, beta_2, final_lr, gamma, epsilon, decay, amsbound, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m                  \u001b[0mamsbound\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                  **kwargs):\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAdaBound\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#.__init__(**kwargs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int64'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'iterations'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: super(type, obj): obj must be an instance or subtype of type"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMv4cuyTm5hc"
      },
      "source": [
        "''' Results '''\n",
        "# eval = model.evaluate(x=x_test_1, y=y_test1)\n",
        "\n",
        "print(history.history)\n",
        "\n",
        "# print(eval)\n",
        "\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.grid(True)\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.grid(True)\n",
        "plt.legend(['Train', 'Test'], loc='upper right')\n",
        "plt.show()\n",
        "\n",
        "evaluation = model_final.evaluate(x=x_test_1, y=y_test1)\n",
        "print(\"test loss, test acc:\", evaluation)\n",
        "\n",
        "print(history.history['val_accuracy'])\n",
        "print(np.max(history.history['val_accuracy']))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
